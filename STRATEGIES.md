# Rate Limiting Strategies

Understanding the different rate limiting algorithms and when to use them.

## Overview

The SDK provides three rate limiting strategies, each with different characteristics and use cases.

## Sliding Window Strategy

### How it Works
- Maintains an array of request timestamps
- Removes expired timestamps on each check
- Most accurate representation of request rate

### Characteristics
- âœ… **Accurate**: Prevents rate limit circumvention
- âœ… **Smooth**: No burst allowance at boundaries
- âŒ **Memory**: Stores all request timestamps
- âŒ **Performance**: O(n) cleanup operations

### Best For
- APIs with strict rate limits
- Security-sensitive applications
- When accuracy is more important than performance

### Example
```typescript
const { makeRequest } = useRateLimiter({
  maxRequests: 100,
  windowMs: 60000,
  strategy: 'sliding-window'
});
```

### Visual Representation
```
Time:     0    10   20   30   40   50   60   70
Requests: |----|----|----|----|----|----|----|----|
Window:        [----------60s window----------]
```

## Fixed Window Strategy

### How it Works
- Simple counter that resets at fixed intervals
- Tracks window start time and request count
- Resets completely when window expires

### Characteristics
- âœ… **Memory**: O(1) memory usage
- âœ… **Performance**: O(1) operations
- âœ… **Simple**: Easy to understand and debug
- âŒ **Bursts**: Allows 2x rate at boundaries

### Best For
- High-performance applications
- Internal APIs with relaxed limits
- When simplicity is preferred

### Example
```typescript
const { makeRequest } = useRateLimiter({
  maxRequests: 100,
  windowMs: 60000,
  strategy: 'fixed-window'
});
```

### Visual Representation
```
Time:     0    30   60   90   120
Requests: 100  100  0    50   0
Window:   [--60s--][--60s--][--60s--]
```

### Burst Problem
At window boundaries, users can make 200 requests in 1 second:
- 100 requests at 59.9s (end of window 1)
- 100 requests at 60.1s (start of window 2)

## Token Bucket Strategy

### How it Works
- Maintains a bucket of tokens
- Tokens refill at constant rate
- Each request consumes one token
- Allows burst up to bucket capacity

### Characteristics
- âœ… **Flexible**: Allows controlled bursts
- âœ… **Smooth**: Natural rate limiting
- âœ… **Efficient**: O(1) operations
- âš ï¸ **Complex**: More parameters to tune

### Best For
- APIs that allow burst traffic
- User-facing applications
- When smooth experience is important

### Example
```typescript
const { makeRequest } = useRateLimiter({
  maxRequests: 100,    // Bucket capacity
  windowMs: 60000,     // Refill period
  strategy: 'token-bucket'
});
```

### Visual Representation
```
Tokens:   100 â†’ 90 â†’ 80 â†’ 85 â†’ 90 â†’ 95 â†’ 100
Time:     0s   1s   2s   3s   4s   5s   6s
Refill:        +5   +5   +5   +5   +5
```

## Strategy Comparison

| Feature | Sliding Window | Fixed Window | Token Bucket |
|---------|---------------|--------------|--------------|
| Accuracy | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ |
| Memory | â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |
| Performance | â­â­ | â­â­â­â­â­ | â­â­â­â­ |
| Burst Control | â­â­â­â­â­ | â­ | â­â­â­â­ |
| Simplicity | â­â­â­ | â­â­â­â­â­ | â­â­â­ |

## Choosing the Right Strategy

### Use Sliding Window When:
- Strict rate limit compliance required
- Security is paramount
- Memory usage is acceptable
- Request volume is moderate

### Use Fixed Window When:
- High performance required
- Simple implementation preferred
- Burst traffic is acceptable
- Internal APIs with relaxed limits

### Use Token Bucket When:
- User experience is important
- Burst traffic should be allowed
- Smooth rate limiting desired
- API supports burst patterns

## Configuration Examples

### Conservative (Security-focused)
```typescript
{
  maxRequests: 50,
  windowMs: 60000,
  strategy: 'sliding-window',
  skipFailedRequests: true
}
```

### Balanced (General purpose)
```typescript
{
  maxRequests: 100,
  windowMs: 60000,
  strategy: 'token-bucket'
}
```

### Performance (High throughput)
```typescript
{
  maxRequests: 1000,
  windowMs: 60000,
  strategy: 'fixed-window',
  skipSuccessfulRequests: false
}
```

## Advanced Patterns

### Adaptive Strategy
```typescript
function useAdaptiveRateLimiter(baseConfig) {
  const [strategy, setStrategy] = useState('token-bucket');
  
  const config = {
    ...baseConfig,
    strategy
  };
  
  // Switch strategy based on conditions
  useEffect(() => {
    if (errorRate > 0.1) {
      setStrategy('sliding-window'); // More strict
    } else if (performance.slow) {
      setStrategy('fixed-window');   // Faster
    }
  }, [errorRate, performance]);
  
  return useRateLimiter(config);
}
```

### Hybrid Approach
```typescript
// Use different strategies for different endpoints
const limiters = useMultiRateLimiter({
  auth: { 
    maxRequests: 5, 
    windowMs: 60000, 
    strategy: 'sliding-window' 
  },
  api: { 
    maxRequests: 100, 
    windowMs: 60000, 
    strategy: 'token-bucket' 
  },
  uploads: { 
    maxRequests: 10, 
    windowMs: 60000, 
    strategy: 'fixed-window' 
  }
});
```


Rate Limiting â€” Deep Understanding with Examples & Scenarios
First: What is Rate Limiting really doing?

At its core, rate limiting answers one question:

â€œShould this request be allowed right now, based on what happened recently?â€

Everything else (sliding window, fixed window, token bucket) is just different ways of defining â€œrecentlyâ€ and â€œhow much is allowed.â€

1ï¸âƒ£ Sliding Window Strategy (Most Accurate, Most Strict)
ğŸ§  Mental Model

Imagine a security guard with a notebook.

Every time you enter, the guard writes down the exact timestamp

Before letting you in again, the guard:

Erases entries older than 60 seconds

Counts how many entries remain

If count â‰¥ limit â†’ âŒ deny entry

This guard never forgets exact timing.

ğŸ” How It Works (Step by Step)

Assume:

maxRequests = 5

windowMs = 60 seconds

Request Time (s)	Stored Timestamps	Allowed?
0	[0]	âœ…
10	[0,10]	âœ…
20	[0,10,20]	âœ…
30	[0,10,20,30]	âœ…
40	[0,10,20,30,40]	âœ…
50	[0,10,20,30,40]	âŒ (limit reached)
61	[10,20,30,40,61]	âœ… (0 expired)

Notice:

Requests expire individually

There is no reset moment

ğŸš« Why It Prevents Abuse

âŒ You cannot cheat by waiting for a window boundary
âŒ You cannot burst more than allowed
âŒ Timing precision matters

This is why itâ€™s called â€œmost accurateâ€.

âš ï¸ Cost of Accuracy

Stores every request timestamp

Cleanup requires scanning timestamps â†’ O(n)

High traffic = more memory & CPU

ğŸ›¡ Real-World Scenarios

Best use cases:

ğŸ” Authentication APIs
/login â†’ 5 attempts per minute


Why?

Prevent brute force attacks

Evenly distributed attempts are blocked

ğŸ’³ Payment APIs
/charge-card â†’ 10 per minute


Why?

Prevent double-spending or fraud

âœ… When YOU should use Sliding Window

âœ” Security-sensitive
âœ” External/public APIs
âœ” Abuse prevention
âœ” Accuracy > performance

2ï¸âƒ£ Fixed Window Strategy (Fastest, Simplest)
ğŸ§  Mental Model

Imagine a turnstile with a counter:

Every minute, the counter resets to 0

Each entry increments the counter

When it hits the limit â†’ âŒ block

When the clock hits the next minute â†’ ğŸ§¹ reset

ğŸ” How It Works

Assume:

maxRequests = 5

windowMs = 60s

Time	Window	Counter	Allowed?
0s	0â€“60	1	âœ…
10s	0â€“60	2	âœ…
50s	0â€“60	5	âœ…
59s	0â€“60	6	âŒ
60s	60â€“120	1	âœ…
ğŸš¨ The Burst Problem (Very Important)

User can do this:

59.9s â†’ 100 requests
60.1s â†’ 100 requests


â¡ 200 requests in ~0.2 seconds

Yet the system thinks everything is fine ğŸ˜¬

âš¡ Why Itâ€™s Still Useful

Constant memory (O(1))

Constant time (O(1))

Extremely fast

Easy to reason about

ğŸ­ Real-World Scenarios
ğŸ§© Internal Microservices
Service A â†’ Service B


Why?

Trusted environment

Performance matters more than abuse

ğŸ“Š Metrics Collection
/metrics â†’ 1000/min


Why?

Bursts are acceptable

Data is aggregated anyway

âœ… When YOU should use Fixed Window

âœ” Internal APIs
âœ” Very high throughput
âœ” Simple logic
âœ” Bursts are acceptable

3ï¸âƒ£ Token Bucket Strategy (Best User Experience)
ğŸ§  Mental Model

Imagine a water bucket:

Bucket has a maximum size

Water drips in steadily

Each request scoops out 1 cup

If bucket is empty â†’ âŒ wait

This allows bursts, but only up to capacity.

ğŸ” How It Works

Assume:

Bucket capacity = 10 tokens

Refill rate = 1 token / second

Time	Tokens	Action	Result
0s	10	5 req	Allowed â†’ 5 left
1s	6	refill	+1 â†’ 6
2s	7	refill	+1
3s	7	3 req	Allowed â†’ 4
4s	4	refill	+1
ğŸ¯ Why Users Love This

Short bursts feel instant

Long-term rate stays controlled

No sudden â€œhard resetsâ€

âš ï¸ Complexity Tradeoff

You must tune:

Bucket size

Refill rate

Bad tuning = either too strict or too lenient

ğŸ§‘â€ğŸ’» Real-World Scenarios
ğŸŒ Public APIs (GitHub, Stripe, OpenAI)
100 requests/min, burst up to 20

ğŸ“± Mobile Apps
User taps refresh multiple times


Why?

Bursts feel natural

No sudden blocking

âœ… When YOU should use Token Bucket

âœ” User-facing apps
âœ” Smooth experience needed
âœ” Bursts allowed but controlled

ğŸ”¥ Real-Life Comparison Scenario
API Limit: 100 requests per minute
User sends requests evenly
Strategy	Result
Sliding Window	âœ… Always allowed
Fixed Window	âœ… Always allowed
Token Bucket	âœ… Always allowed
User sends 100 requests in 2 seconds
Strategy	Result
Sliding Window	âŒ Blocked
Fixed Window	âœ… Allowed
Token Bucket	âœ… Allowed (if capacity â‰¥ 100)
ğŸ§  Decision Cheat Sheet
Situation	Best Strategy
Login / OTP	Sliding Window
Internal services	Fixed Window
Public REST API	Token Bucket
Financial actions	Sliding Window
UI / Mobile	Token Bucket
ğŸ”‘ Final Takeaway (Important)

Sliding Window = Security Guard with Memory

Fixed Window = Simple Counter

Token Bucket = Water Bucket

If you remember those three mental models, you will never confuse them again.